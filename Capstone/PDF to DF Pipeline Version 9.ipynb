{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`!py -3.7 -m pip install PyPDF2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`!py -3.7 -m pip install tika`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`!py -3.7 -m pip install textract`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`!py -3.7 -m pip install pdfplumber`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_pdf(pdf_file):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        for i in range(len(pdf.pages)):\n",
    "            first_page = pdf.pages[i]\n",
    "            #print(first_page.extract_text())\n",
    "            #f.write(first_page.extract_text())\n",
    "            text = text + first_page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker(text):\n",
    "    ticker_start = text.find(\"EDITED TRANSCRIPT\")+18  #EDITED TRANSCRIPT\\\n",
    "    ticker_end = text.find(\" \",ticker_start)\n",
    "    ticker = text[ticker_start:ticker_end]\n",
    "    #print(\"Ticker: \"+ticker)\n",
    "    return ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_presentation(text):    # Need to remove footer, need to remove page count\n",
    "    presentation = (text[text.find(\"PRESENTATION\")+13:text.find(\"QUESTIONS AND ANSWERS\")]) #PRESENTATION\\\n",
    "    return presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['JANUARY','FEBRUARY','MARCH','APRIL','MAY','JUNE','JULY','AUGUST','SEPTEMBER','OCTOBER','NOVEMBER','DECEMBER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime(text):\n",
    "    time_start = text.find(\"EVENT DATE/TIME:\")+17\n",
    "    time_end = text.find(\"/\",time_start)-1\n",
    "    call_date = text[time_start:time_end] #\"EVENT DATE/TIME:\"\n",
    "    year = call_date[-4:]\n",
    "    day = call_date[call_date.find(\" \")+1:call_date.find(\",\")]\n",
    "    month = months.index(call_date[:call_date.find(\" \")])+1\n",
    "    #print(\"Date: \"+call_date)\n",
    "    return [int(year),month,int(day)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quarter(text_datetime):\n",
    "    if text_datetime[1] < 4:\n",
    "        return 1\n",
    "    if text_datetime[1] < 7:\n",
    "        return 2\n",
    "    if text_datetime[1] < 10:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def get_epoch(text_datetime):\n",
    "    return int(datetime.datetime(text_datetime[0],text_datetime[1],text_datetime[2]).timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Price URL Format\n",
    "#url_eg = \"https://query1.finance.yahoo.com/v7/finance/download/<Ticker>?period1=<Start>&period2=<End>&interval=<Number+[d/w/m]>&events=history&includeAdjustedClose=true\"\n",
    "#url_str = \"https://query1.finance.yahoo.com/v7/finance/download/{}?period1={}&period2={}&interval=1&events=history&includeAdjustedClose=true\" #ticker+1st date+2nd date\n",
    "\n",
    "def get_csv_url(ticker,text_date):\n",
    "    epoch1 = get_epoch(text_date) - 604800 # one week before\n",
    "    epoch2 = get_epoch(text_date) + 604800 # one week after\n",
    "    ticker = ticker[:ticker.find('.')]\n",
    "    stock_price = f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={epoch1}&period2={epoch2}&interval=1d&events=history&includeAdjustedClose=true\" #ticker+1st date+2nd date\n",
    "    #debug print(stock_price)\n",
    "    return stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with csv\n",
    "import csv\n",
    "import requests\n",
    "\n",
    "def get_prices_csv(CSV_URL):\n",
    "\n",
    "    with requests.Session() as s:\n",
    "        download = s.get(CSV_URL)\n",
    "\n",
    "        decoded_content = download.content.decode('utf-8')\n",
    "\n",
    "        cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "        my_list = list(cr)\n",
    "        #debug for row in my_list:\n",
    "            #debug print(row)\n",
    "        #print(CSV_URL)\n",
    "        #print(my_list)\n",
    "        return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_csv_date(date):\n",
    "    date = date[0].split('-')\n",
    "    for i in range(3):\n",
    "        date[i] = int(date[i])\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_avg_from_csv(csv_list,text_date):\n",
    "    #Getting days before/since earning calls\n",
    "    new_columns_to_append_to_row_example = []\n",
    "    for i in csv_list[1:]:\n",
    "        average_price = (float(i[1])+float(i[2])+float(i[3])+float(i[4]))/4\n",
    "        relative_date =  (get_epoch(text_date)-get_epoch(convert_csv_date(i)))/86400\n",
    "        new_columns_to_append_to_row_example.append(relative_date)\n",
    "        new_columns_to_append_to_row_example.append(average_price)\n",
    "    #debug print(new_columns_to_append_to_row_example)\n",
    "    # in the array, values are days before/since earning call and stock price\n",
    "\n",
    "    #Price avg of past week, avg of next week\n",
    "    #replace 0's with nearest neighboor\n",
    "    is_date = True\n",
    "    branch = 0\n",
    "    week_before_price = []\n",
    "    earning_call_price = []\n",
    "    week_after_price = []\n",
    "    for i in new_columns_to_append_to_row_example:\n",
    "        if is_date:\n",
    "            is_date = False\n",
    "            if i > 0:\n",
    "                branch = 1\n",
    "            if i == 0:\n",
    "                branch = 2\n",
    "            if i < 0:\n",
    "                branch = 3\n",
    "        else:\n",
    "            is_date = True\n",
    "            if branch == 1:\n",
    "                week_before_price.append(i)\n",
    "            if branch == 2:\n",
    "                earning_call_price.append(i)\n",
    "            if branch == 3:\n",
    "                week_after_price.append(i)\n",
    "    #debug print(week_before_price)\n",
    "    #debug print(sum(week_before_price)/len(week_before_price))\n",
    "    #debug print(earning_call_price)\n",
    "    #debug print(sum(earning_call_price)/len(earning_call_price)) #simplify and account for blanks\n",
    "    #debug print(week_after_price)\n",
    "    #debug print(sum(week_after_price)/len(week_after_price))\n",
    "    return [sum(week_before_price)/len(week_before_price),sum(earning_call_price)/len(earning_call_price),sum(week_after_price)/len(week_after_price)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_row(text,ticker):\n",
    "    date_array = get_datetime(text)\n",
    "    quarter = get_quarter(date_array)\n",
    "    presentation = get_presentation(text)\n",
    "    csv_url = get_csv_url(ticker,date_array)\n",
    "    csv_list = get_prices_csv(csv_url)\n",
    "    prices = get_price_avg_from_csv(csv_list,date_array) #explode?\n",
    "    str_date = [str(i) for i in date_array] # date convert\n",
    "    return ['-'.join(str_date),quarter,ticker,presentation,prices[0],prices[1],prices[2]] #row as array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_row(text,ticker):\n",
    "    try:\n",
    "        date_array = get_datetime(text)\n",
    "    except:\n",
    "        date_array = [0, 0, 0]\n",
    "    try:\n",
    "        quarter = get_quarter(date_array)\n",
    "    except:\n",
    "        quarter = 0\n",
    "    try:\n",
    "        presentation = get_presentation(text)\n",
    "    except:\n",
    "        presentation = text\n",
    "    try:\n",
    "        csv_url = get_csv_url(ticker,date_array)\n",
    "    except:\n",
    "        csv_url = \"FAILED TO GENERATE\"\n",
    "    try:\n",
    "        csv_list = get_prices_csv(csv_url)\n",
    "    except:\n",
    "        csv_list = []\n",
    "    try:\n",
    "        prices = get_price_avg_from_csv(csv_list,date_array) #explode?\n",
    "    except:\n",
    "        prices = [0,0,0]\n",
    "    try:\n",
    "        str_date = [str(i) for i in date_array] # date convert\n",
    "    except:\n",
    "        str_date = [\"NA\",\"NA\",\"NA\"]\n",
    "    return ['-'.join(str_date),quarter,ticker,presentation,prices[0],prices[1],prices[2]] #row as array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year-Month-Day</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Price_Prior</th>\n",
       "      <th>Price_During</th>\n",
       "      <th>Price_After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Year-Month-Day, Quarter, Ticker, Text, Price_Prior, Price_During, Price_After]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['Year-Month-Day','Quarter','Ticker','Text','Price_Prior','Price_During','Price_After'])\n",
    "df_error = df\n",
    "df #ADD Category, History, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through all transcripts in pdf and store error debugging info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_next_chunck(text):\n",
    "    brief = text.find(\"EDITED BRIEF\")\n",
    "    transcript = text.find(\"EDITED TRANSCRIPT\")\n",
    "    if brief == -1:\n",
    "        brief = 9999999\n",
    "    if transcript == -1:\n",
    "        transcript = 9999999   \n",
    "    if brief < transcript:\n",
    "        text = text[brief+2:]\n",
    "    else:\n",
    "        text = text[transcript+2:]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_text(text,identifier):\n",
    "    global df\n",
    "    global df_error\n",
    "    text = cut_next_chunck(text)\n",
    "    while text.find(\"EDITED TRANSCRIPT\") != -1 or text.find(\"EDITED BRIEF\") != -1:\n",
    "        try: #create row\n",
    "            a_series = pd.Series(new_row(text,ticker), index = df.columns)\n",
    "            df = df.append(a_series, ignore_index=True)\n",
    "        except: #create debugging info\n",
    "            print(\"A row failed to be generated\")\n",
    "            a_series =  pd.Series(test_row(text,ticker), index = df_error.columns)\n",
    "            df_error = df_error.append(a_series, ignore_index=True)\n",
    "        text = cut_next_chunck(text)\n",
    "    print(identifier+\" ran and finished.\") #kill task after that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample function for applying to each file in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocess import Pool, Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_child(lock_,df_,df_error_):\n",
    "    global lock\n",
    "    lock = lock_\n",
    "    global df\n",
    "    df = df_\n",
    "    global df_error\n",
    "    df_error = df_error_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_job(filepath):\n",
    "    import pandas as pd\n",
    "    import pdfplumber\n",
    "    \n",
    "    def extract_pdf(pdf_file):\n",
    "        text = \"\"\n",
    "        with pdfplumber.open(pdf_file) as pdf:\n",
    "            for i in range(len(pdf.pages)):\n",
    "                first_page = pdf.pages[i]\n",
    "                text = text + first_page.extract_text()\n",
    "        return text\n",
    "    \n",
    "    def get_ticker(text):\n",
    "        ticker_start = text.find(\"EDITED TRANSCRIPT\")+18  #EDITED TRANSCRIPT\\\n",
    "        ticker_end = text.find(\" \",ticker_start)\n",
    "        ticker = text[ticker_start:ticker_end]\n",
    "        if \".\" not in ticker[-3:]: #PROVISORELY FIXING BUG WITH READING TICKER\n",
    "            ticker = ticker+\".N\"\n",
    "        return ticker\n",
    "    \n",
    "    def get_presentation(text):    # Need to remove footer, need to remove page count\n",
    "        presentation = (text[text.find(\"PRESENTATION\")+13:text.find(\"QUESTIONS AND ANSWERS\")]) #PRESENTATION\\\n",
    "        return presentation\n",
    "    \n",
    "    months = ['JANUARY','FEBRUARY','MARCH','APRIL','MAY','JUNE','JULY','AUGUST','SEPTEMBER','OCTOBER','NOVEMBER','DECEMBER']\n",
    "    \n",
    "    def get_datetime(text):\n",
    "        time_start = text.find(\"EVENT DATE/TIME:\")+17\n",
    "        time_end = text.find(\"/\",time_start)-1\n",
    "        call_date = text[time_start:time_end] #\"EVENT DATE/TIME:\"\n",
    "        year = call_date[-4:]\n",
    "        day = call_date[call_date.find(\" \")+1:call_date.find(\",\")]\n",
    "        month = months.index(call_date[:call_date.find(\" \")])+1\n",
    "        #print(\"Date: \"+call_date)\n",
    "        return [int(year),month,int(day)]\n",
    "    \n",
    "    def get_quarter(text_datetime):\n",
    "        if text_datetime[1] < 4:\n",
    "            return 1\n",
    "        if text_datetime[1] < 7:\n",
    "            return 2\n",
    "        if text_datetime[1] < 10:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4\n",
    "    \n",
    "    import datetime\n",
    "    def get_epoch(text_datetime):\n",
    "        return int(datetime.datetime(text_datetime[0],text_datetime[1],text_datetime[2]).timestamp())\n",
    "    \n",
    "    def get_csv_url(ticker,text_date):\n",
    "        epoch1 = get_epoch(text_date) - 604800 # one week before\n",
    "        epoch2 = get_epoch(text_date) + 604800 # one week after\n",
    "        ticker = ticker[:ticker.find('.')]\n",
    "        stock_price = f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={epoch1}&period2={epoch2}&interval=1d&events=history&includeAdjustedClose=true\" #ticker+1st date+2nd date\n",
    "        return stock_price\n",
    "    \n",
    "    import csv\n",
    "    import requests\n",
    "    def get_prices_csv(CSV_URL):\n",
    "        with requests.Session() as s:\n",
    "            download = s.get(CSV_URL)\n",
    "            decoded_content = download.content.decode('utf-8')\n",
    "            cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "            my_list = list(cr)\n",
    "            return my_list\n",
    "    \n",
    "    def convert_csv_date(date):\n",
    "        date = date[0].split('-')\n",
    "        for i in range(3):\n",
    "            date[i] = int(date[i])\n",
    "        return date\n",
    "    \n",
    "    def get_price_avg_from_csv(csv_list,text_date):\n",
    "        new_columns_to_append_to_row_example = []\n",
    "        for i in csv_list[1:]:\n",
    "            average_price = (float(i[1])+float(i[2])+float(i[3])+float(i[4]))/4\n",
    "            relative_date =  (get_epoch(text_date)-get_epoch(convert_csv_date(i)))/86400\n",
    "            new_columns_to_append_to_row_example.append(relative_date)\n",
    "            new_columns_to_append_to_row_example.append(average_price)\n",
    "\n",
    "        is_date = True\n",
    "        branch = 0\n",
    "        week_before_price = []\n",
    "        earning_call_price = []\n",
    "        week_after_price = []\n",
    "        for i in new_columns_to_append_to_row_example:\n",
    "            if is_date:\n",
    "                is_date = False\n",
    "                if i > 0:\n",
    "                    branch = 1\n",
    "                if i == 0:\n",
    "                    branch = 2\n",
    "                if i < 0:\n",
    "                    branch = 3\n",
    "            else:\n",
    "                is_date = True\n",
    "                if branch == 1:\n",
    "                    week_before_price.append(i)\n",
    "                if branch == 2:\n",
    "                    earning_call_price.append(i)\n",
    "                if branch == 3:\n",
    "                    week_after_price.append(i)\n",
    "        return [sum(week_before_price)/len(week_before_price),sum(earning_call_price)/len(earning_call_price),sum(week_after_price)/len(week_after_price)]\n",
    "    \n",
    "    def new_row(text,ticker):\n",
    "        date_array = get_datetime(text)\n",
    "        quarter = get_quarter(date_array)\n",
    "        presentation = get_presentation(text)\n",
    "        csv_url = get_csv_url(ticker,date_array)\n",
    "        csv_list = get_prices_csv(csv_url)\n",
    "        prices = get_price_avg_from_csv(csv_list,date_array) #explode?\n",
    "        str_date = [str(i) for i in date_array] # date convert\n",
    "        return ['-'.join(str_date),quarter,ticker,presentation,prices[0],prices[1],prices[2]] #row as array\n",
    "    \n",
    "    def test_row(text,ticker):\n",
    "        try:\n",
    "            date_array = get_datetime(text)\n",
    "        except:\n",
    "            date_array = [0, 0, 0]\n",
    "        try:\n",
    "            quarter = get_quarter(date_array)\n",
    "        except:\n",
    "            quarter = 0\n",
    "        try:\n",
    "            presentation = get_presentation(text)\n",
    "        except:\n",
    "            presentation = text\n",
    "        try:\n",
    "            csv_url = get_csv_url(ticker,date_array)\n",
    "        except:\n",
    "            csv_url = \"FAILED TO GENERATE\"\n",
    "        try:\n",
    "            csv_list = get_prices_csv(csv_url)\n",
    "        except:\n",
    "            csv_list = []\n",
    "        try:\n",
    "            prices = get_price_avg_from_csv(csv_list,date_array) #explode?\n",
    "        except:\n",
    "            prices = [0,0,0]\n",
    "        try:\n",
    "            str_date = [str(i) for i in date_array] # date convert\n",
    "        except:\n",
    "            str_date = [\"NA\",\"NA\",\"NA\"]\n",
    "        return ['-'.join(str_date),quarter,ticker,presentation,prices[0],prices[1],prices[2]] #row as array\n",
    "    \n",
    "    def cut_next_chunck(text):\n",
    "        brief = text.find(\"EDITED BRIEF\")\n",
    "        transcript = text.find(\"EDITED TRANSCRIPT\")\n",
    "        if brief == -1:\n",
    "            brief = 9999999\n",
    "        if transcript == -1:\n",
    "            transcript = 9999999   \n",
    "        if brief < transcript:\n",
    "            text = text[brief+2:]\n",
    "        else:\n",
    "            text = text[transcript+2:]\n",
    "        return text\n",
    "    \n",
    "    def extract_from_text(text,identifier):\n",
    "        global df\n",
    "        global df_error\n",
    "        text = cut_next_chunck(text)\n",
    "        while text.find(\"EDITED TRANSCRIPT\") != -1 or text.find(\"EDITED BRIEF\") != -1:\n",
    "            try: #create row\n",
    "                a_series = pd.Series(new_row(text,ticker), index = df.columns)\n",
    "                df = df.append(a_series, ignore_index=True)\n",
    "            except: #create debugging info\n",
    "                print(\"A row failed to be generated\")\n",
    "                a_series =  pd.Series(test_row(text,ticker), index = df_error.columns)\n",
    "                df_error = df_error.append(a_series, ignore_index=True)\n",
    "            text = cut_next_chunck(text)\n",
    "        print(identifier+\" ran and finished.\") #kill task after that\n",
    "    \n",
    "    text = extract_pdf(filepath)\n",
    "    ticker = get_ticker(text)\n",
    "    extract_from_text(text,\"alpha\")\n",
    "    return [df, df_error]\n",
    "\n",
    "def create_pool(filepaths):\n",
    "    filepaths = filepaths #[:6]\n",
    "    global dfs\n",
    "    global to_concat\n",
    "    global to_concat_error\n",
    "    lock = Lock()\n",
    "    poolsize = 6\n",
    "    with Pool(poolsize, initializer=init_child, initargs=(lock,df,df_error,)) as pool:\n",
    "        print(filepaths)\n",
    "        dfs = pool.imap_unordered(do_job, filepaths)\n",
    "        to_concat = []\n",
    "        to_concat_error = []\n",
    "        \n",
    "        for dftuple in dfs:\n",
    "            to_concat.append(dftuple[0])\n",
    "            to_concat_error.append(dftuple[1])\n",
    "        print(\"DONE on create_poll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:/Downloads/Conference Call data 2\\\\AAPL.pdf', 'D:/Downloads/Conference Call data 2\\\\ABBV_1.pdf', 'D:/Downloads/Conference Call data 2\\\\ABBV_2.pdf', 'D:/Downloads/Conference Call data 2\\\\ABT_1.pdf', 'D:/Downloads/Conference Call data 2\\\\ACN.pdf', 'D:/Downloads/Conference Call data 2\\\\ADBE_1.pdf', 'D:/Downloads/Conference Call data 2\\\\AMGN_1.pdf', 'D:/Downloads/Conference Call data 2\\\\AMGN_2.pdf', 'D:/Downloads/Conference Call data 2\\\\AMGN_3.pdf', 'D:/Downloads/Conference Call data 2\\\\AVGO.pdf', 'D:/Downloads/Conference Call data 2\\\\BAC_1.pdf', 'D:/Downloads/Conference Call data 2\\\\BAC_2.pdf', 'D:/Downloads/Conference Call data 2\\\\BA_1.pdf', 'D:/Downloads/Conference Call data 2\\\\BA_2.pdf', 'D:/Downloads/Conference Call data 2\\\\BMY_1.pdf', 'D:/Downloads/Conference Call data 2\\\\BMY_2.pdf', 'D:/Downloads/Conference Call data 2\\\\CAT_1.pdf', 'D:/Downloads/Conference Call data 2\\\\CMCSA_1.pdf', 'D:/Downloads/Conference Call data 2\\\\CMCSA_2.pdf', 'D:/Downloads/Conference Call data 2\\\\COST_1.pdf', 'D:/Downloads/Conference Call data 2\\\\COST_2.pdf', 'D:/Downloads/Conference Call data 2\\\\CRM_1.pdf', 'D:/Downloads/Conference Call data 2\\\\CRM_2.pdf', 'D:/Downloads/Conference Call data 2\\\\CRM_3.pdf', 'D:/Downloads/Conference Call data 2\\\\CSCO_1.pdf', 'D:/Downloads/Conference Call data 2\\\\CSCO_2.pdf', 'D:/Downloads/Conference Call data 2\\\\C_1.pdf', 'D:/Downloads/Conference Call data 2\\\\C_2.pdf', 'D:/Downloads/Conference Call data 2\\\\C_3.pdf', 'D:/Downloads/Conference Call data 2\\\\DHR_1.pdf', 'D:/Downloads/Conference Call data 2\\\\DHR_2.pdf', 'D:/Downloads/Conference Call data 2\\\\DHR_3.pdf', 'D:/Downloads/Conference Call data 2\\\\DIS_1.pdf', 'D:/Downloads/Conference Call data 2\\\\GE_1.pdf', 'D:/Downloads/Conference Call data 2\\\\GE_2.pdf', 'D:/Downloads/Conference Call data 2\\\\GS_1.pdf', 'D:/Downloads/Conference Call data 2\\\\HD_1.pdf', 'D:/Downloads/Conference Call data 2\\\\HON_1.pdf', 'D:/Downloads/Conference Call data 2\\\\HON_2.pdf', 'D:/Downloads/Conference Call data 2\\\\INTC_1.pdf', 'D:/Downloads/Conference Call data 2\\\\INTC_2.pdf', 'D:/Downloads/Conference Call data 2\\\\INTU_1.pdf', 'D:/Downloads/Conference Call data 2\\\\JNJ_1.pdf', 'D:/Downloads/Conference Call data 2\\\\JNJ_2.pdf', 'D:/Downloads/Conference Call data 2\\\\JPM_1.pdf', 'D:/Downloads/Conference Call data 2\\\\JPM_2.pdf', 'D:/Downloads/Conference Call data 2\\\\KO_1.pdf', 'D:/Downloads/Conference Call data 2\\\\KO_2.pdf', 'D:/Downloads/Conference Call data 2\\\\LIN.pdf', 'D:/Downloads/Conference Call data 2\\\\LLY_1.pdf', 'D:/Downloads/Conference Call data 2\\\\LLY_2.pdf', 'D:/Downloads/Conference Call data 2\\\\Lowe_1.pdf', 'D:/Downloads/Conference Call data 2\\\\MA_1.pdf', 'D:/Downloads/Conference Call data 2\\\\MA_2.pdf', 'D:/Downloads/Conference Call data 2\\\\MCD_1.pdf', 'D:/Downloads/Conference Call data 2\\\\MDT_1.pdf', 'D:/Downloads/Conference Call data 2\\\\MDT_2.pdf', 'D:/Downloads/Conference Call data 2\\\\MDT_3.pdf', 'D:/Downloads/Conference Call data 2\\\\MRK_1.pdf', 'D:/Downloads/Conference Call data 2\\\\MRK_2.pdf', 'D:/Downloads/Conference Call data 2\\\\MSFT_1.pdf', 'D:/Downloads/Conference Call data 2\\\\MSFT_2.pdf', 'D:/Downloads/Conference Call data 2\\\\MS_1.pdf', 'D:/Downloads/Conference Call data 2\\\\MS_2.pdf', 'D:/Downloads/Conference Call data 2\\\\NEE_1.pdf', 'D:/Downloads/Conference Call data 2\\\\NFLX.pdf', 'D:/Downloads/Conference Call data 2\\\\NKE.pdf', 'D:/Downloads/Conference Call data 2\\\\NVDA_1.pdf', 'D:/Downloads/Conference Call data 2\\\\NVDA_2.pdf', 'D:/Downloads/Conference Call data 2\\\\ORCL_1.pdf', 'D:/Downloads/Conference Call data 2\\\\PEP.pdf', 'D:/Downloads/Conference Call data 2\\\\PFE_1.pdf', 'D:/Downloads/Conference Call data 2\\\\PFE_2.pdf', 'D:/Downloads/Conference Call data 2\\\\PG_1.pdf', 'D:/Downloads/Conference Call data 2\\\\PG_2.pdf', 'D:/Downloads/Conference Call data 2\\\\PM_1.pdf', 'D:/Downloads/Conference Call data 2\\\\PYPL_1.pdf', 'D:/Downloads/Conference Call data 2\\\\PYPL_2.pdf', 'D:/Downloads/Conference Call data 2\\\\QCOM_1.pdf', 'D:/Downloads/Conference Call data 2\\\\QCOM_2.pdf', 'D:/Downloads/Conference Call data 2\\\\SBUX_1.pdf', 'D:/Downloads/Conference Call data 2\\\\TMO_1.pdf', 'D:/Downloads/Conference Call data 2\\\\TMO_2.pdf', 'D:/Downloads/Conference Call data 2\\\\TSLA.pdf', 'D:/Downloads/Conference Call data 2\\\\TXN_1.pdf', 'D:/Downloads/Conference Call data 2\\\\TXN_2.pdf', 'D:/Downloads/Conference Call data 2\\\\T_1.pdf', 'D:/Downloads/Conference Call data 2\\\\T_2.pdf', 'D:/Downloads/Conference Call data 2\\\\T_3.pdf', 'D:/Downloads/Conference Call data 2\\\\UNH_1.pdf', 'D:/Downloads/Conference Call data 2\\\\UNP_1.pdf', 'D:/Downloads/Conference Call data 2\\\\UNP_2.pdf', 'D:/Downloads/Conference Call data 2\\\\UPS.pdf', 'D:/Downloads/Conference Call data 2\\\\VZ_1.pdf', 'D:/Downloads/Conference Call data 2\\\\VZ_2.pdf', 'D:/Downloads/Conference Call data 2\\\\WFC_1.pdf', 'D:/Downloads/Conference Call data 2\\\\WFC_2.pdf', 'D:/Downloads/Conference Call data 2\\\\WMT_1.pdf', 'D:/Downloads/Conference Call data 2\\\\XOM_1.pdf']\n",
      "DONE on create_poll\n",
      "It is DONE\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# Print pdf files in folder\n",
    "dfs = []\n",
    "filepaths = glob.glob(r'D:/Downloads/Conference Call data 2/*.pdf')\n",
    "create_pool(filepaths)\n",
    "print(\"It is DONE\")\n",
    "#do_job(filepaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype of code for downloading price for stock and converting dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year-Month-Day</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Price_Prior</th>\n",
       "      <th>Price_During</th>\n",
       "      <th>Price_After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-5-9</td>\n",
       "      <td>2</td>\n",
       "      <td>ABBV.N</td>\n",
       "      <td>Gregory B. Gilbert - Deutsche Bank AG, Researc...</td>\n",
       "      <td>100.064999</td>\n",
       "      <td>100.390001</td>\n",
       "      <td>104.073125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-4-26</td>\n",
       "      <td>2</td>\n",
       "      <td>ABBV.N</td>\n",
       "      <td>Operator\\nGood morning, and thank you for stan...</td>\n",
       "      <td>92.584500</td>\n",
       "      <td>95.892502</td>\n",
       "      <td>99.713126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-4-26</td>\n",
       "      <td>2</td>\n",
       "      <td>ABBV.N</td>\n",
       "      <td>SUMMARY\\nI. 1Q18 REVIEW (R.G.)\\nA. Highlights:...</td>\n",
       "      <td>92.584500</td>\n",
       "      <td>95.892502</td>\n",
       "      <td>99.713126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-3-15</td>\n",
       "      <td>1</td>\n",
       "      <td>ABBV.N</td>\n",
       "      <td>Geoffrey Christopher Meacham - Barclays Bank P...</td>\n",
       "      <td>118.544500</td>\n",
       "      <td>117.077499</td>\n",
       "      <td>113.309375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-1-26</td>\n",
       "      <td>1</td>\n",
       "      <td>ABBV.N</td>\n",
       "      <td>Operator\\nGood morning, and thank you for stan...</td>\n",
       "      <td>105.629500</td>\n",
       "      <td>119.267500</td>\n",
       "      <td>117.132500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>2017-4-28</td>\n",
       "      <td>2</td>\n",
       "      <td>XOM.N</td>\n",
       "      <td>Operator\\nGood day, everyone, and welcome to t...</td>\n",
       "      <td>81.263501</td>\n",
       "      <td>82.039999</td>\n",
       "      <td>82.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2017-4-28</td>\n",
       "      <td>2</td>\n",
       "      <td>XOM.N</td>\n",
       "      <td>SUMMARY\\nI. 1Q17 REVIEW (J.W.)\\nA. Headlines:\\...</td>\n",
       "      <td>81.263501</td>\n",
       "      <td>82.039999</td>\n",
       "      <td>82.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>2017-3-1</td>\n",
       "      <td>1</td>\n",
       "      <td>XOM.N</td>\n",
       "      <td>Jeff Woodbury - ExxonMobil Corporation - VP, I...</td>\n",
       "      <td>81.396000</td>\n",
       "      <td>82.437498</td>\n",
       "      <td>82.895001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>2017-1-31</td>\n",
       "      <td>1</td>\n",
       "      <td>XOM.N</td>\n",
       "      <td>Operator\\nGood day, everyone, and welcome to t...</td>\n",
       "      <td>85.296500</td>\n",
       "      <td>84.282499</td>\n",
       "      <td>83.355001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>2017-1-31</td>\n",
       "      <td>1</td>\n",
       "      <td>XOM.N</td>\n",
       "      <td>SUMMARY\\nI. 4Q16 REVIEW (J.W.)\\nA. Headlines:\\...</td>\n",
       "      <td>85.296500</td>\n",
       "      <td>84.282499</td>\n",
       "      <td>83.355001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38064 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year-Month-Day Quarter  Ticker  \\\n",
       "0         2018-5-9       2  ABBV.N   \n",
       "1        2018-4-26       2  ABBV.N   \n",
       "2        2018-4-26       2  ABBV.N   \n",
       "3        2018-3-15       1  ABBV.N   \n",
       "4        2018-1-26       1  ABBV.N   \n",
       "..             ...     ...     ...   \n",
       "743      2017-4-28       2   XOM.N   \n",
       "744      2017-4-28       2   XOM.N   \n",
       "745       2017-3-1       1   XOM.N   \n",
       "746      2017-1-31       1   XOM.N   \n",
       "747      2017-1-31       1   XOM.N   \n",
       "\n",
       "                                                  Text  Price_Prior  \\\n",
       "0    Gregory B. Gilbert - Deutsche Bank AG, Researc...   100.064999   \n",
       "1    Operator\\nGood morning, and thank you for stan...    92.584500   \n",
       "2    SUMMARY\\nI. 1Q18 REVIEW (R.G.)\\nA. Highlights:...    92.584500   \n",
       "3    Geoffrey Christopher Meacham - Barclays Bank P...   118.544500   \n",
       "4    Operator\\nGood morning, and thank you for stan...   105.629500   \n",
       "..                                                 ...          ...   \n",
       "743  Operator\\nGood day, everyone, and welcome to t...    81.263501   \n",
       "744  SUMMARY\\nI. 1Q17 REVIEW (J.W.)\\nA. Headlines:\\...    81.263501   \n",
       "745  Jeff Woodbury - ExxonMobil Corporation - VP, I...    81.396000   \n",
       "746  Operator\\nGood day, everyone, and welcome to t...    85.296500   \n",
       "747  SUMMARY\\nI. 4Q16 REVIEW (J.W.)\\nA. Headlines:\\...    85.296500   \n",
       "\n",
       "     Price_During  Price_After  \n",
       "0      100.390001   104.073125  \n",
       "1       95.892502    99.713126  \n",
       "2       95.892502    99.713126  \n",
       "3      117.077499   113.309375  \n",
       "4      119.267500   117.132500  \n",
       "..            ...          ...  \n",
       "743     82.039999    82.080000  \n",
       "744     82.039999    82.080000  \n",
       "745     82.437498    82.895001  \n",
       "746     84.282499    83.355001  \n",
       "747     84.282499    83.355001  \n",
       "\n",
       "[38064 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(to_concat)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year-Month-Day</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Text</th>\n",
       "      <th>Price_Prior</th>\n",
       "      <th>Price_During</th>\n",
       "      <th>Price_After</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-1-30</td>\n",
       "      <td>1</td>\n",
       "      <td>AMGN.OQ</td>\n",
       "      <td>Operator\\nMy name is Cindy, and I'll be your c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-9-20</td>\n",
       "      <td>3</td>\n",
       "      <td>AMGN.OQ</td>\n",
       "      <td>Operator\\nGood afternoon. My name is Annie, an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-9-28</td>\n",
       "      <td>3</td>\n",
       "      <td>AMGN.OQ</td>\n",
       "      <td>Operator\\nMy name is Mary, and I will be your ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-9-8</td>\n",
       "      <td>3</td>\n",
       "      <td>AMGN.OQ</td>\n",
       "      <td>Operator\\nMy name is Mary, and I will be your ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-9</td>\n",
       "      <td>4</td>\n",
       "      <td>AMGN.N</td>\n",
       "      <td>Arvind Sood - Amgen Inc. - VP of IR\\nOkay, I t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-12-5</td>\n",
       "      <td>4</td>\n",
       "      <td>C.N</td>\n",
       "      <td>Richard Nigel Ramsden - Goldman Sachs Group In...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-6-3</td>\n",
       "      <td>2</td>\n",
       "      <td>LLY.N</td>\n",
       "      <td>Operator\\nLadies and gentlemen, thank you for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-6-3</td>\n",
       "      <td>2</td>\n",
       "      <td>LLY.N</td>\n",
       "      <td>SUMMARY\\nI. INTRODUCTION (S.M.)\\nA. Overview:\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-6-10</td>\n",
       "      <td>2</td>\n",
       "      <td>MDT.N</td>\n",
       "      <td>Ryan Weispfenning - Medtronic plc - VP of IR\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-12-5</td>\n",
       "      <td>4</td>\n",
       "      <td>TXN.OQ</td>\n",
       "      <td>Blayne Peter Curtis - Barclays Bank PLC, Resea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year-Month-Day Quarter   Ticker  \\\n",
       "0       2021-1-30       1  AMGN.OQ   \n",
       "1       2020-9-20       3  AMGN.OQ   \n",
       "2       2019-9-28       3  AMGN.OQ   \n",
       "3        2019-9-8       3  AMGN.OQ   \n",
       "0       2017-12-9       4   AMGN.N   \n",
       "..            ...     ...      ...   \n",
       "5       2018-12-5       4      C.N   \n",
       "6        2017-6-3       2    LLY.N   \n",
       "7        2017-6-3       2    LLY.N   \n",
       "8       2017-6-10       2    MDT.N   \n",
       "9       2018-12-5       4   TXN.OQ   \n",
       "\n",
       "                                                 Text Price_Prior  \\\n",
       "0   Operator\\nMy name is Cindy, and I'll be your c...           0   \n",
       "1   Operator\\nGood afternoon. My name is Annie, an...           0   \n",
       "2   Operator\\nMy name is Mary, and I will be your ...           0   \n",
       "3   Operator\\nMy name is Mary, and I will be your ...           0   \n",
       "0   Arvind Sood - Amgen Inc. - VP of IR\\nOkay, I t...           0   \n",
       "..                                                ...         ...   \n",
       "5   Richard Nigel Ramsden - Goldman Sachs Group In...           0   \n",
       "6   Operator\\nLadies and gentlemen, thank you for ...           0   \n",
       "7   SUMMARY\\nI. INTRODUCTION (S.M.)\\nA. Overview:\\...           0   \n",
       "8   Ryan Weispfenning - Medtronic plc - VP of IR\\n...           0   \n",
       "9   Blayne Peter Curtis - Barclays Bank PLC, Resea...           0   \n",
       "\n",
       "   Price_During Price_After  \n",
       "0             0           0  \n",
       "1             0           0  \n",
       "2             0           0  \n",
       "3             0           0  \n",
       "0             0           0  \n",
       "..          ...         ...  \n",
       "5             0           0  \n",
       "6             0           0  \n",
       "7             0           0  \n",
       "8             0           0  \n",
       "9             0           0  \n",
       "\n",
       "[374 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error = pd.concat(to_concat_error)\n",
    "df_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"CallData1V9.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error.to_excel(\"CallData1V9Errors.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
